{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, os, tqdm, random, sys, shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_root = '/mnt/d/Github/mmdetection2/project/LogMiniDet/data'\n",
    "root_img = '/mnt/d/Github/mmdetection2/project/LogMiniDet/data/train/images'\n",
    "root_save = '/mnt/d/Github/mmdetection2/project/LogMiniDet/data/0428'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_datasets(annos, root_img, root_save, prob=0.8, type='COCO'):\n",
    "    # only support COCO annotations\n",
    "    if prob >= 1 or prob <=0:\n",
    "        print('The range of prob is (0, 1)!')\n",
    "        return None\n",
    "    if os.path.exists(annos) == False:\n",
    "        print('Please check the path of annotations file!')\n",
    "        return None\n",
    "    if os.path.exists(root_img) == False:\n",
    "        print('Please check the path of image root!')\n",
    "        return None\n",
    "    if type == 'COCO':\n",
    "        with open(annos, 'r') as f:\n",
    "            data = json.load(f)\n",
    "        info = data['info']\n",
    "        license = data['license']\n",
    "        images = data['images']\n",
    "        annotations = data['annotations']\n",
    "        categories = data['categories']\n",
    "        print('info:{}\\nlicense:{}'.format(info, license))\n",
    "        print('The datasets have {} images, {} annotations'.format(len(images), len(annotations)))\n",
    "        train_set = {\n",
    "            'info': info,\n",
    "            'license': license,\n",
    "            'images': [],\n",
    "            'annotations':[],\n",
    "            'categories': categories,\n",
    "        }\n",
    "        val_set = {\n",
    "            'info': info,\n",
    "            'license': license,\n",
    "            'images': [],\n",
    "            'annotations':[],\n",
    "            'categories': categories,\n",
    "        }\n",
    "        if os.path.exists(root_save) == False:\n",
    "            os.mkdir(root_save)\n",
    "        os.mkdir(os.path.join(root_save, 'train'))\n",
    "        os.mkdir(os.path.join(root_save, 'val'))\n",
    "        os.mkdir(os.path.join(root_save, 'annotations'))\n",
    "        train_img_id = val_img_id = 0\n",
    "        train_anno_id = val_anno_id = 0\n",
    "        for image in tqdm.tqdm(images):\n",
    "            temp_img = image\n",
    "            temp_img_id = image['id']\n",
    "            temp_annos = []\n",
    "            if random.random() < prob:\n",
    "                # taining set\n",
    "                temp_img['id'] = train_img_id\n",
    "                train_img_id += 1\n",
    "                for anno in annotations:\n",
    "                    if anno['image_id'] == temp_img_id:\n",
    "                        temp_anno = anno\n",
    "                        temp_anno['id'] = train_anno_id\n",
    "                        temp_anno['image_id'] = temp_img_id\n",
    "                        train_anno_id += 1\n",
    "                        temp_annos.append(temp_anno)\n",
    "                    if anno['image_id'] > temp_img_id:\n",
    "                        break\n",
    "                train_set['images'].append(temp_img)\n",
    "                train_set['annotations'].extend(temp_annos)\n",
    "                # copy image\n",
    "                shutil.copyfile(os.path.join(root_img,temp_img['file_name']), os.path.join(root_save,'train/'+temp_img['file_name']))\n",
    "            else:\n",
    "                # valing set\n",
    "                temp_img['id'] = val_img_id\n",
    "                val_img_id += 1\n",
    "                for anno in annotations:\n",
    "                    if anno['image_id'] == temp_img_id:\n",
    "                        temp_anno = anno\n",
    "                        temp_anno['id'] = val_anno_id\n",
    "                        temp_anno['image_id'] = temp_img_id\n",
    "                        val_anno_id += 1\n",
    "                        temp_annos.append(temp_anno)\n",
    "                    if anno['image_id'] > temp_img_id:\n",
    "                        break\n",
    "                val_set['images'].append(temp_img)\n",
    "                val_set['annotations'].extend(temp_annos)\n",
    "                # copy image\n",
    "                shutil.copyfile(os.path.join(root_img,temp_img['file_name']), os.path.join(root_save,'val/'+temp_img['file_name']))\n",
    "        \n",
    "        print('The train set has {} images, {} annotations'.format(len(train_set['images']), len(train_set['annotations'])))\n",
    "        print('The val set has {} images, {} annotations'.format(len(val_set['images']), len(val_set['annotations'])))\n",
    "        # save annotations\n",
    "        with open(os.path.join(root_save, 'annotations/train.json'), 'w') as f:\n",
    "            json.dump(train_set, f)\n",
    "        with open(os.path.join(root_save, 'annotations/val.json'), 'w') as f:\n",
    "            json.dump(val_set, f)\n",
    "    else:\n",
    "        print('The annotation style of {} has not supported right now.'.format(type))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "info:spytensor created\n",
      "license:['license']\n",
      "The datasets have 2476 images, 5161 annotations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2476/2476 [03:15<00:00, 12.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train set has 1986 images, 4151 annotations\n",
      "The val set has 490 images, 1010 annotations\n"
     ]
    }
   ],
   "source": [
    "anno_file = os.path.join(file_root, 'train/annotations/instances_train2017.json')\n",
    "split_datasets(anno_file, root_img, root_save, prob=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'a': 1, 'b': 2}]\n"
     ]
    }
   ],
   "source": [
    "a={'a':1,'b':2}\n",
    "b=[]\n",
    "b.append(a)\n",
    "print(b)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5e3dd4b29ba3876cd119e45faa2b3cc45bdb4befedc6229feaaf2d9a451ee344"
  },
  "kernelspec": {
   "display_name": "Python 3.7.9 ('mmdet2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
