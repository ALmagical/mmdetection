{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, os, tqdm, random, sys, shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_root = '/root/autodl-tmp/Dataset/LogMiniDet/data'\n",
    "root_img = file_root + '/train/images'\n",
    "root_save = file_root + '/0506'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_datasets(annos, root_img, root_save, prob=0.8, type='COCO'):\n",
    "    # only support COCO annotations\n",
    "    if prob >= 1 or prob <=0:\n",
    "        print('The range of prob is (0, 1)!')\n",
    "        return None\n",
    "    if os.path.exists(annos) == False:\n",
    "        print('Please check the path of annotations file!')\n",
    "        return None\n",
    "    if os.path.exists(root_img) == False:\n",
    "        print('Please check the path of image root!')\n",
    "        return None\n",
    "    if type == 'COCO':\n",
    "        with open(annos, 'r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "        info = data['info']\n",
    "        license = data['license']\n",
    "        images = data['images']\n",
    "        annotations = data['annotations']\n",
    "        categories = data['categories']\n",
    "        print('info:{}\\nlicense:{}'.format(info, license))\n",
    "        print('The datasets have {} images, {} annotations'.format(len(images), len(annotations)))\n",
    "        train_set = {\n",
    "            'info': info,\n",
    "            'license': license,\n",
    "            'images': [],\n",
    "            'annotations':[],\n",
    "            'categories': categories,\n",
    "        }\n",
    "        val_set = {\n",
    "            'info': info,\n",
    "            'license': license,\n",
    "            'images': [],\n",
    "            'annotations':[],\n",
    "            'categories': categories,\n",
    "        }\n",
    "        if os.path.exists(root_save) == False:\n",
    "            os.mkdir(root_save)\n",
    "        os.mkdir(os.path.join(root_save, 'train'))\n",
    "        os.mkdir(os.path.join(root_save, 'val'))\n",
    "        os.mkdir(os.path.join(root_save, 'annotations'))\n",
    "        train_img_id = val_img_id = 0\n",
    "        train_anno_id = val_anno_id = 0\n",
    "        for image in tqdm.tqdm(images):\n",
    "            temp_img = image\n",
    "            temp_img_id = image['id']\n",
    "            temp_annos = []\n",
    "            if random.random() < prob:\n",
    "                # taining set\n",
    "                temp_img['id'] = train_img_id\n",
    "                train_img_id += 1\n",
    "                for anno in annotations:\n",
    "                    if anno['image_id'] == temp_img_id:\n",
    "                        temp_anno = anno\n",
    "                        temp_anno['id'] = train_anno_id\n",
    "                        temp_anno['image_id'] = temp_img['id']\n",
    "                        train_anno_id += 1\n",
    "                        temp_annos.append(temp_anno)\n",
    "                    if anno['image_id'] > temp_img_id:\n",
    "                        break\n",
    "                train_set['images'].append(temp_img)\n",
    "                train_set['annotations'].extend(temp_annos)\n",
    "                # copy image\n",
    "                shutil.copyfile(os.path.join(root_img,temp_img['file_name']), os.path.join(root_save,'train/'+temp_img['file_name']))\n",
    "            else:\n",
    "                # valing set\n",
    "                temp_img['id'] = val_img_id\n",
    "                val_img_id += 1\n",
    "                for anno in annotations:\n",
    "                    if anno['image_id'] == temp_img_id:\n",
    "                        temp_anno = anno\n",
    "                        temp_anno['id'] = val_anno_id\n",
    "                        temp_anno['image_id'] = temp_img['id']\n",
    "                        val_anno_id += 1\n",
    "                        temp_annos.append(temp_anno)\n",
    "                    if anno['image_id'] > temp_img_id:\n",
    "                        break\n",
    "                val_set['images'].append(temp_img)\n",
    "                val_set['annotations'].extend(temp_annos)\n",
    "                # copy image\n",
    "                shutil.copyfile(os.path.join(root_img,temp_img['file_name']), os.path.join(root_save,'val/'+temp_img['file_name']))\n",
    "        \n",
    "        print('The train set has {} images, {} annotations'.format(len(train_set['images']), len(train_set['annotations'])))\n",
    "        print('The val set has {} images, {} annotations'.format(len(val_set['images']), len(val_set['annotations'])))\n",
    "        # save annotations\n",
    "        with open(os.path.join(root_save, 'annotations/train.json'), 'w', encoding='utf-8') as f:\n",
    "            json.dump(train_set, f)\n",
    "        with open(os.path.join(root_save, 'annotations/val.json'), 'w', encoding='utf-8') as f:\n",
    "            json.dump(val_set, f)\n",
    "    else:\n",
    "        print('The annotation style of {} has not supported right now.'.format(type))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "info:spytensor created\n",
      "license:['license']\n",
      "The datasets have 2476 images, 5161 annotations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2476 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/root/autodl-tmp/Dataset/LogMiniDet/data/train/images/0218a27cab43f45df80e26195da5599b.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/root/autodl-tmp/code/mmdetection/project/tools/split_datasets.ipynb Cell 4'\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bregion-3.autodl.com/root/autodl-tmp/code/mmdetection/project/tools/split_datasets.ipynb#ch0000003vscode-remote?line=0'>1</a>\u001b[0m anno_file \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(file_root, \u001b[39m'\u001b[39m\u001b[39mtrain/annotations/instances_train2017.json\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bregion-3.autodl.com/root/autodl-tmp/code/mmdetection/project/tools/split_datasets.ipynb#ch0000003vscode-remote?line=1'>2</a>\u001b[0m split_datasets(anno_file, root_img, root_save, prob\u001b[39m=\u001b[39;49m\u001b[39m0.9\u001b[39;49m)\n",
      "\u001b[1;32m/root/autodl-tmp/code/mmdetection/project/tools/split_datasets.ipynb Cell 3'\u001b[0m in \u001b[0;36msplit_datasets\u001b[0;34m(annos, root_img, root_save, prob, type)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bregion-3.autodl.com/root/autodl-tmp/code/mmdetection/project/tools/split_datasets.ipynb#ch0000002vscode-remote?line=60'>61</a>\u001b[0m     train_set[\u001b[39m'\u001b[39m\u001b[39mannotations\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mextend(temp_annos)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bregion-3.autodl.com/root/autodl-tmp/code/mmdetection/project/tools/split_datasets.ipynb#ch0000002vscode-remote?line=61'>62</a>\u001b[0m     \u001b[39m# copy image\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bregion-3.autodl.com/root/autodl-tmp/code/mmdetection/project/tools/split_datasets.ipynb#ch0000002vscode-remote?line=62'>63</a>\u001b[0m     shutil\u001b[39m.\u001b[39;49mcopyfile(os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mjoin(root_img,temp_img[\u001b[39m'\u001b[39;49m\u001b[39mfile_name\u001b[39;49m\u001b[39m'\u001b[39;49m]), os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mjoin(root_save,\u001b[39m'\u001b[39;49m\u001b[39mtrain/\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m+\u001b[39;49mtemp_img[\u001b[39m'\u001b[39;49m\u001b[39mfile_name\u001b[39;49m\u001b[39m'\u001b[39;49m]))\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bregion-3.autodl.com/root/autodl-tmp/code/mmdetection/project/tools/split_datasets.ipynb#ch0000002vscode-remote?line=63'>64</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bregion-3.autodl.com/root/autodl-tmp/code/mmdetection/project/tools/split_datasets.ipynb#ch0000002vscode-remote?line=64'>65</a>\u001b[0m     \u001b[39m# valing set\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bregion-3.autodl.com/root/autodl-tmp/code/mmdetection/project/tools/split_datasets.ipynb#ch0000002vscode-remote?line=65'>66</a>\u001b[0m     temp_img[\u001b[39m'\u001b[39m\u001b[39mid\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m val_img_id\n",
      "File \u001b[0;32m~/miniconda3/envs/mmdet/lib/python3.9/shutil.py:264\u001b[0m, in \u001b[0;36mcopyfile\u001b[0;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[1;32m    <a href='file:///root/miniconda3/envs/mmdet/lib/python3.9/shutil.py?line=261'>262</a>\u001b[0m     os\u001b[39m.\u001b[39msymlink(os\u001b[39m.\u001b[39mreadlink(src), dst)\n\u001b[1;32m    <a href='file:///root/miniconda3/envs/mmdet/lib/python3.9/shutil.py?line=262'>263</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///root/miniconda3/envs/mmdet/lib/python3.9/shutil.py?line=263'>264</a>\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39;49m(src, \u001b[39m'\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mas\u001b[39;00m fsrc:\n\u001b[1;32m    <a href='file:///root/miniconda3/envs/mmdet/lib/python3.9/shutil.py?line=264'>265</a>\u001b[0m         \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    <a href='file:///root/miniconda3/envs/mmdet/lib/python3.9/shutil.py?line=265'>266</a>\u001b[0m             \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(dst, \u001b[39m'\u001b[39m\u001b[39mwb\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m fdst:\n\u001b[1;32m    <a href='file:///root/miniconda3/envs/mmdet/lib/python3.9/shutil.py?line=266'>267</a>\u001b[0m                 \u001b[39m# macOS\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/root/autodl-tmp/Dataset/LogMiniDet/data/train/images/0218a27cab43f45df80e26195da5599b.jpg'"
     ]
    }
   ],
   "source": [
    "anno_file = os.path.join(file_root, 'train/annotations/instances_train2017.json')\n",
    "split_datasets(anno_file, root_img, root_save, prob=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'a': 1, 'b': 2}]\n"
     ]
    }
   ],
   "source": [
    "a={'a':1,'b':2}\n",
    "b=[]\n",
    "b.append(a)\n",
    "print(b)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5e3dd4b29ba3876cd119e45faa2b3cc45bdb4befedc6229feaaf2d9a451ee344"
  },
  "kernelspec": {
   "display_name": "mmdet",
   "language": "python",
   "name": "mmdet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
